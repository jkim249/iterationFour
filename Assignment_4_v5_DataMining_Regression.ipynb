{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Data_Importance').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------------------+---+----------+-------+------+--------------+--------------+---------------+\n",
      "|Dog_Number|Primary_Colour_Code|Secondary_Colour_Code|Age|Animal_Sex|Desexed|Worker|Classification|Microchip_Flag|Total_Complains|\n",
      "+----------+-------------------+---------------------+---+----------+-------+------+--------------+--------------+---------------+\n",
      "|    151010|               DARK|                 DARK|  0|         F|      Y|     N|             0|             Y|              0|\n",
      "|    173567|               DARK|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    192345|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             N|              0|\n",
      "|    193685|              LIGHT|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    218377|              LIGHT|                 DARK|  0|         M|      Y|     N|             0|             Y|              0|\n",
      "|    222071|               DARK|                LIGHT|  0|         F|      Y|     N|             0|             Y|              0|\n",
      "|    223603|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    234035|               DARK|                 DARK|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    234169|              LIGHT|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    234737|               DARK|                LIGHT|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    235290|               DARK|                LIGHT|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    235610|               DARK|                LIGHT|  0|         M|      Y|     N|             0|             Y|              0|\n",
      "|    235789|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    236387|              LIGHT|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    237924|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             N|              0|\n",
      "|     41157|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             N|              0|\n",
      "|     93545|               DARK|                 DARK|  0|         M|      N|     N|             0|             N|              0|\n",
      "|    100576|               DARK|                LIGHT|  0|         F|      N|     N|             0|             N|              0|\n",
      "|    101167|               DARK|                 DARK|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    124353|               DARK|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "+----------+-------------------+---------------------+---+----------+-------+------+--------------+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's read in the data. Note that it's in the format of JSON.\n",
    "dog_data_merged = spark.read.load(\"Datasets/Dog_registred_hamilton_new_v1_2_6.csv\", format=\"csv\", header =\"true\")\n",
    "dog_data_merged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Dog_Number: string (nullable = true)\n",
      " |-- Primary_Colour_Code: string (nullable = true)\n",
      " |-- Secondary_Colour_Code: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Animal_Sex: string (nullable = true)\n",
      " |-- Desexed: string (nullable = true)\n",
      " |-- Worker: string (nullable = true)\n",
      " |-- Classification: string (nullable = true)\n",
      " |-- Microchip_Flag: string (nullable = true)\n",
      " |-- Total_Complains: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dog_data_merged.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "dog_data_merged = dog_data_merged.withColumn(\"Dog_Number\",dog_data_merged[\"Dog_Number\"].cast(IntegerType()))\n",
    "dog_data_merged = dog_data_merged.withColumn(\"Age\",dog_data_merged[\"Age\"].cast(IntegerType()))\n",
    "dog_data_merged = dog_data_merged.withColumn(\"Total_Complains\",dog_data_merged[\"Total_Complains\"].cast(IntegerType()))\n",
    "dog_data_merged = dog_data_merged.withColumn(\"Classification\",dog_data_merged[\"Classification\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Dog_Number: integer (nullable = true)\n",
      " |-- Primary_Colour_Code: string (nullable = true)\n",
      " |-- Secondary_Colour_Code: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Animal_Sex: string (nullable = true)\n",
      " |-- Desexed: string (nullable = true)\n",
      " |-- Worker: string (nullable = true)\n",
      " |-- Classification: integer (nullable = true)\n",
      " |-- Microchip_Flag: string (nullable = true)\n",
      " |-- Total_Complains: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dog_data_merged.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Classification|count|\n",
      "+--------------+-----+\n",
      "|             1| 1504|\n",
      "|             0|57545|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dog_data_merged.groupBy(\"Classification\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 38\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "\n",
    "major_df = dog_data_merged.filter(col(\"Classification\") == 0)\n",
    "minor_df = dog_data_merged.filter(col(\"Classification\") == 1)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------------------+---+----------+-------+------+--------------+--------------+---------------+\n",
      "|Dog_Number|Primary_Colour_Code|Secondary_Colour_Code|Age|Animal_Sex|Desexed|Worker|Classification|Microchip_Flag|Total_Complains|\n",
      "+----------+-------------------+---------------------+---+----------+-------+------+--------------+--------------+---------------+\n",
      "|    151010|               DARK|                 DARK|  0|         F|      Y|     N|             0|             Y|              0|\n",
      "|    173567|               DARK|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    192345|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             N|              0|\n",
      "|    193685|              LIGHT|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    218377|              LIGHT|                 DARK|  0|         M|      Y|     N|             0|             Y|              0|\n",
      "|    222071|               DARK|                LIGHT|  0|         F|      Y|     N|             0|             Y|              0|\n",
      "|    223603|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    234035|               DARK|                 DARK|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    234169|              LIGHT|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    234737|               DARK|                LIGHT|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    235290|               DARK|                LIGHT|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    235610|               DARK|                LIGHT|  0|         M|      Y|     N|             0|             Y|              0|\n",
      "|    235789|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    236387|              LIGHT|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "|    237924|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             N|              0|\n",
      "|     41157|              LIGHT|                LIGHT|  0|         F|      N|     N|             0|             N|              0|\n",
      "|     93545|               DARK|                 DARK|  0|         M|      N|     N|             0|             N|              0|\n",
      "|    100576|               DARK|                LIGHT|  0|         F|      N|     N|             0|             N|              0|\n",
      "|    101167|               DARK|                 DARK|  0|         F|      N|     N|             0|             Y|              0|\n",
      "|    124353|               DARK|                LIGHT|  0|         M|      N|     N|             0|             Y|              0|\n",
      "+----------+-------------------+---------------------+---+----------+-------+------+--------------+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = range(ratio)\n",
    "# duplicate the minority rows\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n",
    "# combine both oversampled minority rows and previous majority rows \n",
    "combined_data = major_df.unionAll(oversampled_df)\n",
    "combined_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Classification|count|\n",
      "+--------------+-----+\n",
      "|             1|57152|\n",
      "|             0|57545|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_data.groupBy(\"Classification\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dog_Number',\n",
       " 'Primary_Colour_Code',\n",
       " 'Secondary_Colour_Code',\n",
       " 'Age',\n",
       " 'Animal_Sex',\n",
       " 'Desexed',\n",
       " 'Worker',\n",
       " 'Classification',\n",
       " 'Microchip_Flag',\n",
       " 'Total_Complains']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_data.select(['Primary_Colour_Code',\n",
    " 'Secondary_Colour_Code',\n",
    " 'Age',\n",
    " 'Animal_Sex',\n",
    " 'Desexed',\n",
    " 'Classification',\n",
    " 'Microchip_Flag',\n",
    " 'Total_Complains'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_colour_indexer = StringIndexer(inputCol='Primary_Colour_Code',\\\n",
    "                                       outputCol='Primary_Colour_Code_Index',)\n",
    "primary_colour_encoder = OneHotEncoder(inputCol='Primary_Colour_Code_Index',\\\n",
    "                                       outputCol='Primary_Colour_Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_colour_indexer = StringIndexer(inputCol='Secondary_Colour_Code',\\\n",
    "                                         outputCol='Secondary_Colour_Code_Index', )\n",
    "secondary_colour_encoder = OneHotEncoder(inputCol='Secondary_Colour_Code_Index',\\\n",
    "                                         outputCol='Secondary_Colour_Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_indexer = StringIndexer(inputCol='Animal_Sex',\\\n",
    "                                       outputCol='Animal_Sex_Index', )\n",
    "sex_encoder = OneHotEncoder(inputCol='Animal_Sex_Index',\\\n",
    "                                       outputCol='Animal_Sex_Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "desexed_indexer = StringIndexer(inputCol='Desexed',\\\n",
    "                                       outputCol='Desexed_Index', )\n",
    "desexed_encoder = OneHotEncoder(inputCol='Desexed_Index', outputCol='Desexed_Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "microchip_flag_indexer = StringIndexer(inputCol='Microchip_Flag',\\\n",
    "                                       outputCol='Microchip_Flag_Index', )\n",
    "microchip_flag_encoder = OneHotEncoder(inputCol='Microchip_Flag_Index',\\\n",
    "                                       outputCol='Microchip_Flag_Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Primary_Colour_Vec',\n",
    " 'Secondary_Colour_Vec','Age','Animal_Sex_Vec','Desexed_Vec','Microchip_Flag_Vec','Total_Complains'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_bite = LogisticRegression(featuresCol='features',labelCol='Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = [primary_colour_indexer, secondary_colour_indexer, sex_indexer,\n",
    "                            desexed_indexer, microchip_flag_indexer,\n",
    "                           primary_colour_encoder, secondary_colour_encoder, sex_encoder,\n",
    "                            desexed_encoder, microchip_flag_encoder, \n",
    "                            assembler, log_reg_bite])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 80459\n",
      "Test Dataset Count: 34238\n"
     ]
    }
   ],
   "source": [
    "train_bite_data, test_bite_data = combined_data.randomSplit([0.7,.3])\n",
    "print(\"Training Dataset Count: \" + str(train_bite_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_bite_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = pipeline.fit(train_bite_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_model.transform(test_bite_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                       labelCol='Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8092084931644584"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC = my_eval.evaluate(results)\n",
    "\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Primary_Colour_Code',\n",
       " 'Secondary_Colour_Code',\n",
       " 'Age',\n",
       " 'Animal_Sex',\n",
       " 'Desexed',\n",
       " 'Classification',\n",
       " 'Microchip_Flag',\n",
       " 'Total_Complains',\n",
       " 'Primary_Colour_Code_Index',\n",
       " 'Secondary_Colour_Code_Index',\n",
       " 'Animal_Sex_Index',\n",
       " 'Desexed_Index',\n",
       " 'Microchip_Flag_Index',\n",
       " 'Primary_Colour_Vec',\n",
       " 'Secondary_Colour_Vec',\n",
       " 'Animal_Sex_Vec',\n",
       " 'Desexed_Vec',\n",
       " 'Microchip_Flag_Vec',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 34238\n",
      "Total Correct: 27705\n",
      "Total Wrong: 6533\n",
      "Correct Ratio: 0.809188620830656\n",
      "Wrong Ratio: 0.19081137916934401\n"
     ]
    }
   ],
   "source": [
    "totalResults = results.select('Classification','prediction')\n",
    "\n",
    "correctResults = totalResults.filter(totalResults['Classification'] == totalResults['prediction'])\n",
    "\n",
    "wrongResults = totalResults.filter(totalResults['Classification'] != totalResults['prediction'])\n",
    "\n",
    "countTR = totalResults.count()\n",
    "print(\"Correct: \" + str(countTR))\n",
    "\n",
    "countTC = correctResults.count()\n",
    "print(\"Total Correct: \" + str(countTC))\n",
    "\n",
    "countTW = wrongResults.count()\n",
    "print(\"Total Wrong: \" + str(countTW))\n",
    "\n",
    "ratioCorrect = countTC / countTR\n",
    "print(\"Correct Ratio: \" + str(ratioCorrect))\n",
    "\n",
    "ratioWrong = countTW / countTR\n",
    "print(\"Wrong Ratio: \" + str(ratioWrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
