{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Data_Importance').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's read in the data. Note that it's in the format of JSON.\n",
    "dog_data_merged = spark.read.load(\"Datasets/Dog_registred_hamilton_new_v1_2_6.csv\", format=\"csv\", header =\"true\")\n",
    "dog_data_merged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dog_data_merged.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "dog_data_merged = dog_data_merged.withColumn(\"Dog_Number\",dog_data_merged[\"Dog_Number\"].cast(IntegerType()))\n",
    "dog_data_merged = dog_data_merged.withColumn(\"Age\",dog_data_merged[\"Age\"].cast(IntegerType()))\n",
    "dog_data_merged = dog_data_merged.withColumn(\"Total_Complains\",dog_data_merged[\"Total_Complains\"].cast(IntegerType()))\n",
    "dog_data_merged = dog_data_merged.withColumn(\"Classification\",dog_data_merged[\"Classification\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dog_data_merged.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_data_merged.groupBy(\"Classification\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "\n",
    "major_df = dog_data_merged.filter(col(\"Classification\") == 0)\n",
    "minor_df = dog_data_merged.filter(col(\"Classification\") == 1)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = range(ratio)\n",
    "# duplicate the minority rows\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n",
    "# combine both oversampled minority rows and previous majority rows \n",
    "combined_data = major_df.unionAll(oversampled_df)\n",
    "combined_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.groupBy(\"Classification\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_data.select(['Primary_Colour_Code',\n",
    " 'Secondary_Colour_Code',\n",
    " 'Age',\n",
    " 'Animal_Sex',\n",
    " 'Desexed',\n",
    " 'Classification',\n",
    " 'Microchip_Flag',\n",
    " 'Total_Complains'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_colour_indexer = StringIndexer(inputCol='Primary_Colour_Code',\\\n",
    "                                       outputCol='Primary_Colour_Code_Index')\n",
    "primary_colour_indexed = primary_colour_indexer.fit(combined_data).transform(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_colour_indexer = StringIndexer(inputCol='Secondary_Colour_Code',\\\n",
    "                                         outputCol='Secondary_Colour_Code_Index')\n",
    "secondary_colour_indexd = secondary_colour_indexer.fit(primary_colour_indexed).transform(primary_colour_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_indexer = StringIndexer(inputCol='Animal_Sex',\\\n",
    "                                       outputCol='Animal_Sex_Index')\n",
    "sex_indexed = sex_indexer.fit(secondary_colour_indexd).transform(secondary_colour_indexd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desexed_indexer = StringIndexer(inputCol='Desexed',\\\n",
    "                                       outputCol='Desexed_Index')\n",
    "desexed_indexd = desexed_indexer.fit(sex_indexed).transform(sex_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microchip_flag_indexer = StringIndexer(inputCol='Microchip_Flag',\\\n",
    "                                       outputCol='Microchip_Flag_Index')\n",
    "\n",
    "microchip_flag_indexd = microchip_flag_indexer.fit(desexed_indexd).transform(desexed_indexd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=\n",
    "                            ['Age','Total_Complains', 'Primary_Colour_Code_Index',\n",
    "            'Secondary_Colour_Code_Index', 'Animal_Sex_Index', 'Desexed_Index',\n",
    "            'Microchip_Flag_Index',], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(microchip_flag_indexd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select(\"features\",'Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='Classification',featuresCol='features', maxDepth=3)\n",
    "rfc = RandomForestClassifier(labelCol='Classification',featuresCol='features')\n",
    "gbt = GBTClassifier(labelCol='Classification',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions = dtc_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binary_gbt_eval = BinaryClassificationEvaluator(labelCol='Classification', rawPredictionCol='prediction')\n",
    "dtc_eva = my_binary_eval.evaluate(dtc_predictions)\n",
    "rfc_eva = my_binary_eval.evaluate(rfc_predictions)\n",
    "gbt_eva = my_binary_gbt_eval.evaluate(gbt_predictions)\n",
    "\n",
    "print(\"Here are the BinaryClassification results!\")\n",
    "print('-'*40)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_eva*100))\n",
    "print('-'*40)\n",
    "print('A random forest ensemble has an accuracy of: {0:2.2f}%'.format(rfc_eva*100))\n",
    "print('-'*40)\n",
    "print('An ensemble using GBT has an accuracy of: {0:2.2f}%'.format(gbt_eva*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"Classification\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "gbt_acc = acc_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Here are the MulticalssBinary results!\")\n",
    "print('-'*40)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*40)\n",
    "print('A random forest ensemble has an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*40)\n",
    "print('An ensemble using GBT has an accuracy of: {0:2.2f}%'.format(gbt_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtc_model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
